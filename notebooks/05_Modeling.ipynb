{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ba882d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d21bb7",
   "metadata": {},
   "source": [
    "## Navigation\n",
    "<ul>\n",
    "<li><a href=\"#oversampling\">Oversampling using SMOTE</a></li>\n",
    "<li><a href=\"#lr\">Logistic Regression model</a></li>\n",
    "    <ul>\n",
    "      <li><a href=\"#thresh\">Threshold adjustment</a></li>\n",
    "    </ul>\n",
    "\n",
    "<li><a href=\"#rf\">Random Forest model</a></li>\n",
    "<li><a href=\"#knn\">K-Nearest Neighbor model</a></li>\n",
    "<li><a href=\"#xgbm\">XGBoost model</a></li>\n",
    "<li><a href=\"#voting\">Ensembling: Voting Classifier</a></li>\n",
    "    <ul>\n",
    "    <li><a href=\"#majority\">Majority voting</a></li>\n",
    "    <li><a href=\"#average\">Average voting</a></li>\n",
    "    </ul>\n",
    "<li><a href=\"#xgb\">Final fit</a></li>\n",
    "<li><a href=\"#joblib\">Export joblib</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad56c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn.over_sampling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c77ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb6962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df.drop(\"LOAN_DEFAULT\" , axis = 1)\n",
    "y = df[\"LOAN_DEFAULT\"]\n",
    "X_train , X_val , y_train , y_val = train_test_split(X, y, test_size = 0.2, random_state=7)\n",
    "# X_train_sub_set , X_vald_sub_set , y_train_sub_set , y_vald_sub_set = train_test_split(x[0:1000], y[0:1000] , test_size = 0.2, random_state=42)\n",
    "\n",
    "# scaling data\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_val_scaled = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b9dbec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.779556\n",
       "1    0.220444\n",
       "Name: LOAN_DEFAULT, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for imbalance\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cddd2f",
   "metadata": {},
   "source": [
    "> Data is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc31af",
   "metadata": {},
   "source": [
    "## Oversampling using SMOTE\n",
    "<a id='oversampling'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bbda11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdulium/miniconda3/envs/t5/lib/python3.7/site-packages/imblearn/utils/_validation.py:300: UserWarning: After over-sampling, the number of samples (153784) in class 1 will be larger than the number of samples in the majority class (class #0 -> 135558)\n",
      "  f\"After over-sampling, the number of samples ({n_samples})\"\n"
     ]
    }
   ],
   "source": [
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "ratio = {1 : n_pos * 4, 0 : n_neg} \n",
    "\n",
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy=ratio, random_state = 10)\n",
    "X_tr_smote, y_tr_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c1b28c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.531496\n",
       "0    0.468504\n",
       "Name: LOAN_DEFAULT, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_smote.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b087960",
   "metadata": {},
   "source": [
    "# Logistics Regression\n",
    "<a id='lr'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0be67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.6364855430597701\n",
      "validation score: 0.46002482644476117\n",
      "**************************************************\n",
      "Training classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.49      0.56    135558\n",
      "           1       0.63      0.77      0.69    153784\n",
      "\n",
      "    accuracy                           0.64    289342\n",
      "   macro avg       0.64      0.63      0.62    289342\n",
      "weighted avg       0.64      0.64      0.63    289342\n",
      "\n",
      "**************************************************\n",
      "Validation classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.40      0.54     34000\n",
      "           1       0.24      0.67      0.35      9502\n",
      "\n",
      "    accuracy                           0.46     43502\n",
      "   macro avg       0.53      0.54      0.44     43502\n",
      "weighted avg       0.69      0.46      0.50     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SMOTE\n",
    "lr = LogisticRegression(C=0.01, penalty='l2', solver='lbfgs')\n",
    "lr.fit(ss.fit_transform(X_tr_smote), y_tr_smote)\n",
    "y_train_pred = lr.predict(ss.fit_transform(X_tr_smote))\n",
    "y_val_pred = lr.predict(X_val_scaled)\n",
    "print(f\"training score: {lr.score(ss.fit_transform(X_tr_smote), y_tr_smote)}\")\n",
    "print(f\"validation score: {lr.score(X_val_scaled, y_val)}\")\n",
    "print(\"*\"*50)\n",
    "print(\"Training classification report\")\n",
    "print(classification_report(y_tr_smote, y_train_pred))\n",
    "print(\"*\"*50)\n",
    "print(\"Validation classification report\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913a5b4",
   "metadata": {},
   "source": [
    "### Perform threshhold adjustment to see if there is any changes\n",
    "<a id='thresh'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e6e48037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model best F1 score 0.364 at prob decision threshold >= 0.324\n"
     ]
    }
   ],
   "source": [
    "thresh_ps = np.linspace(.10,.50,1000)\n",
    "model_val_probs = lr.predict_proba(ss.fit_transform(X_val))[:,1] # positive class probs\n",
    "\n",
    "f1_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    f1_scores.append(f1_score(y_val, model_val_labels))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "\n",
    "best_f1_score = np.max(f1_scores) \n",
    "best_thresh_p = thresh_ps[np.argmax(f1_scores)]\n",
    "\n",
    "print('Logistic Regression Model best F1 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_f1_score, best_thresh_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fe9439e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.12      0.21     34000\n",
      "           1       0.23      0.92      0.36      9502\n",
      "\n",
      "    accuracy                           0.30     43502\n",
      "   macro avg       0.54      0.52      0.29     43502\n",
      "weighted avg       0.71      0.30      0.25     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, lr.predict_proba(ss.fit_transform(X_val))[:,1]>=0.324))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a179e",
   "metadata": {},
   "source": [
    "> Cutoff is showing worst results; therefore, discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b52b9",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "<a id='rf'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae36728c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74    135558\n",
      "           1       0.75      0.89      0.82    153784\n",
      "\n",
      "    accuracy                           0.79    289342\n",
      "   macro avg       0.80      0.78      0.78    289342\n",
      "weighted avg       0.80      0.79      0.78    289342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Best params:  {'max_depth': 25, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 250}\n",
    "# Best estimator:  RandomForestClassifier(max_depth=25, min_samples_leaf=2, n_estimators=250,\n",
    "#                        random_state=7)\n",
    "    \n",
    "rf = RandomForestClassifier(max_depth=25, min_samples_leaf=2, n_estimators=250,\n",
    "                       random_state=7, n_jobs=-1)\n",
    "rf.fit(X_tr_smote, y_tr_smote)\n",
    "y_train_pred = rf.predict(X_tr_smote)\n",
    "print(classification_report(y_tr_smote, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e71c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69     34000\n",
      "           1       0.26      0.50      0.34      9502\n",
      "\n",
      "    accuracy                           0.58     43502\n",
      "   macro avg       0.54      0.55      0.52     43502\n",
      "weighted avg       0.69      0.58      0.61     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = rf.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b020c0",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor\n",
    "<a id='knn'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889a7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=24, metric='euclidean', n_jobs=-1)\n",
    "knn.fit(ss.fit_transform(X_tr_smote), y_tr_smote)\n",
    "y_train_pred = knn.predict(ss.fit_transform(X_tr_smote))\n",
    "y_val_pred = knn.predict(ss.fit_transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86fd406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67    135558\n",
      "           1       0.71      0.71      0.71    153784\n",
      "\n",
      "    accuracy                           0.69    289342\n",
      "   macro avg       0.69      0.69      0.69    289342\n",
      "weighted avg       0.69      0.69      0.69    289342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_tr_smote, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52946823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70     26516\n",
      "           1       0.43      0.24      0.31     16986\n",
      "\n",
      "    accuracy                           0.58     43502\n",
      "   macro avg       0.53      0.52      0.51     43502\n",
      "weighted avg       0.55      0.58      0.55     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56fa72",
   "metadata": {},
   "source": [
    "# XGBoost model\n",
    "<a id='xgbm'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e95e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdulium/miniconda3/envs/t5/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:13:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:13:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=25, min_samples_leaf=2, n_estimators=250, learning_rate=0.1)\n",
    "xgb.fit(X_tr_smote, y_tr_smote)\n",
    "y_train_pred = xgb.predict(X_tr_smote)\n",
    "y_val_pred = xgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb3d2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92    135558\n",
      "           1       0.90      0.97      0.93    153784\n",
      "\n",
      "    accuracy                           0.93    289342\n",
      "   macro avg       0.93      0.92      0.93    289342\n",
      "weighted avg       0.93      0.93      0.93    289342\n",
      "\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75     34000\n",
      "           1       0.25      0.35      0.29      9502\n",
      "\n",
      "    accuracy                           0.63     43502\n",
      "   macro avg       0.52      0.53      0.52     43502\n",
      "weighted avg       0.68      0.63      0.65     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_tr_smote, y_train_pred))\n",
    "print(\"*\"*50)\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187e236",
   "metadata": {},
   "source": [
    "# Voting Classifier\n",
    "<a id='voting'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ee7be",
   "metadata": {},
   "source": [
    "### Majority voting\n",
    "<a id='majority'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11633ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76    135558\n",
      "           1       0.78      0.79      0.79    153784\n",
      "\n",
      "    accuracy                           0.77    289342\n",
      "   macro avg       0.77      0.77      0.77    289342\n",
      "weighted avg       0.77      0.77      0.77    289342\n",
      "\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.49      0.61     34000\n",
      "           1       0.24      0.58      0.34      9502\n",
      "\n",
      "    accuracy                           0.51     43502\n",
      "   macro avg       0.53      0.54      0.48     43502\n",
      "weighted avg       0.69      0.51      0.55     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier([\n",
    "    ('lr' , lr) ,\n",
    "    ('rf' , rf) ,\n",
    "    ('knn' , knn) ,\n",
    "    ('xgb', xgb)\n",
    "    ], voting='hard', n_jobs=-1 )\n",
    "model.fit(ss.fit_transform(X_tr_smote), y_tr_smote)\n",
    "y_train_pred = model.predict(ss.fit_transform(X_tr_smote))\n",
    "y_val_pred = model.predict(ss.fit_transform(X_val))\n",
    "print(classification_report(y_tr_smote, y_train_pred))\n",
    "print(\"*\"*50)\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e32243",
   "metadata": {},
   "source": [
    "### Average voting\n",
    "<a id='average'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6753e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79    135558\n",
      "           1       0.78      0.91      0.84    153784\n",
      "\n",
      "    accuracy                           0.82    289342\n",
      "   macro avg       0.83      0.81      0.81    289342\n",
      "weighted avg       0.83      0.82      0.82    289342\n",
      "\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.46      0.59     34000\n",
      "           1       0.24      0.62      0.35      9502\n",
      "\n",
      "    accuracy                           0.49     43502\n",
      "   macro avg       0.53      0.54      0.47     43502\n",
      "weighted avg       0.69      0.49      0.54     43502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier([\n",
    "    ('lr' , lr) ,\n",
    "    ('rf' , rf) ,\n",
    "    ('knn' , knn) ,\n",
    "    ('xgb', xgb)\n",
    "    ], voting='soft', n_jobs=-1 )\n",
    "model.fit(ss.fit_transform(X_tr_smote), y_tr_smote)\n",
    "y_train_pred = model.predict(ss.fit_transform(X_tr_smote))\n",
    "y_val_pred = model.predict(ss.fit_transform(X_val))\n",
    "print(classification_report(y_tr_smote, y_train_pred))\n",
    "print(\"*\"*50)\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65222f",
   "metadata": {},
   "source": [
    "> Based on our results above, we confidently going to choose XGBoost since our measure here is better F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19af98",
   "metadata": {},
   "source": [
    "# Fit XGBoost on test data\n",
    "<a id='final'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76994642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge train and validation\n",
    "val = X_val.merge(y_val, left_index=True, right_index=True)\n",
    "train = X_tr_smote.merge(y_tr_smote, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "625133c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "30231786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test csv\n",
    "test = pd.read_csv(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a19f4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"LOAN_DEFAULT\" , axis = 1)\n",
    "y = train[\"LOAN_DEFAULT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b31ab7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(\"LOAN_DEFAULT\" , axis = 1)\n",
    "y_test = test[\"LOAN_DEFAULT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4d0802a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdulium/miniconda3/envs/t5/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dff91e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "530db964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68     36303\n",
      "           1       0.65      0.65      0.65     33654\n",
      "\n",
      "    accuracy                           0.67     69957\n",
      "   macro avg       0.66      0.66      0.66     69957\n",
      "weighted avg       0.67      0.67      0.67     69957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f412ee1",
   "metadata": {},
   "source": [
    "> Slight improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6dd29",
   "metadata": {},
   "source": [
    "# Export models to joblib file\n",
    "<a id='joblib'></a>\n",
    "<a href=\"#\">Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cbcaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "models = [\"lr\", \"knn\", \"rf\", \"xgb\"]\n",
    "\n",
    "for model in models:\n",
    "    filename = f'../models/{model}.sav'\n",
    "    joblib.dump(eval(model), filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5",
   "language": "python",
   "name": "t5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
